# config.yml
general:
  model_code: "llm"  # 模型代码
  llm_retrieved_path: "/data/testmodel/LlamaRec/experiments/lru/games"  # 模型路径
  dataset_code: "books"  # 数据集代码
  log_level: "INFO"  # 日志级别
  log_file: "distributed_system.log"  # 日志文件名

process_types:
  LLMScheduler: 1  # LLMScheduler 进程数量
  CacheCoordinator: 1  # CacheCoordinator 进程数量
  Worker: 2  # Worker 进程数量
  KVCache: 2  # KVCache 进程数量

grpc:
  master_addr: "192.168.189.8"  # Grpc主地址
  master_port: 50051  # 默认主端口
  slots: # 1G网控制，每个机器起几个进程
  # 2机配置
  - "192.168.189.8 slots=2"
  - "192.168.189.7 slots=2"
  - "192.168.189.10 slots=2"
  # 4机的配置
  # - "192.168.189.8 slots=4"
  # - "192.168.189.7 slots=2"
  # - "192.168.189.9 slots=2"
  # - "192.168.189.10 slots=2"

distributed:
  master_addr: "127.0.0.1"  # RDMA主地址 没用到
  master_port: "29503" # 好像也没用到
  rank_to_ip_rdma: # 写死还是太麻烦了，以后改成从rank_to_ip生成
  # 2机配置
  - '10.0.0.2' # 0
  - '10.0.0.2' # 1
  - '10.0.0.1' # 2
  - '10.0.0.1' # 3
  - '10.0.0.4' # 4
  - '10.0.0.4' # 5  
  # 4机配置
  # - '10.0.0.2' # 0
  # - '10.0.0.2' # 1
  # - '10.0.0.2' # 2
  # - '10.0.0.2' # 3
  # - '10.0.0.1' # 4
  # - '10.0.0.1' # 5
  # - '10.0.0.3' # 6
  # - '10.0.0.3' # 7
  # - '10.0.0.4' # 8
  # - '10.0.0.4' # 9

kv_cache:
  max_workers: 20  # KVCache 的最大线程池大小
  cache_size: 6200000  # 缓存大小
  page_size: 50  # 页面大小
  p0_scale: 0.7  # L1缓存大小
  p1_scale: 0.8  # L2缓存大小

worker:
  max_workers: 20  # KVCache 的最大线程池大小
  cache_size: 200000  # 缓存大小
  page_size: 50  # 页面大小

coordinator:
  gc_interval: 1  # 垃圾回收间隔
  ttl_interval: 10  # TTL间隔
  prepare_data_path: "/share/nfs/wsh/Bi-KV/Bi-KV/data/books/prepare_cache_data.json"

scheduler:
  max_batch_token: 4000  # 最大批处理Token数
  batch_size: 512 # 批处理大小
  iter_round: 50  # 迭代轮数

input_generator:
  user_history_expand_ratio: 10
  recommendation_size: 100